{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38-hDL_qyNgD"
   },
   "source": [
    "# Matrix completion and recommender systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAQg0dnYQv7w"
   },
   "source": [
    "[MovieLens](movielens.umn.edu) data sets were collected by the [GroupLens Research Project](http://www.grouplens.org/) at the University of Minnesota.\n",
    "\n",
    "This data set consists of:\n",
    "\n",
    "- 100000 ratings (1-5) from 943 users on 1682 movies.\n",
    "- Each user has rated at least 20 movies.\n",
    "\n",
    "The `movielens.csv` file contains the full dataset. Users and items are numbered consecutively from 1. The data is randomly ordered. This is a tab separated list of\n",
    "\n",
    "```\n",
    "user id | item id | rating | timestamp\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1666349397149,
     "user_tz": -120
    },
    "id": "CErbjjHvR85c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hSllBeQSGNd"
   },
   "source": [
    "Read the dataset from the `movielens.csv` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 213,
     "status": "ok",
     "timestamp": 1666349397662,
     "user_tz": -120
    },
    "id": "BGUGfjrcSNFE",
    "outputId": "115e09ba-8c22-4152-a965-db4bbc01cfd1"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\n",
    "    \"./movielens.csv\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"],\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KL3LYjZjSUkE"
   },
   "source": [
    "How many movies? How many people? How many ratings?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1666349397663,
     "user_tz": -120
    },
    "id": "Zkain10kSbQi",
    "outputId": "4d52ca76-db01-4cb4-e21b-3f77bbfddf12"
   },
   "outputs": [],
   "source": [
    "n_people = np.unique(dataset.user_id).size\n",
    "n_movies = np.unique(dataset.item_id).size\n",
    "n_ratings = len(dataset)\n",
    "\n",
    "print(f\"{n_people} people\")\n",
    "print(f\"{n_movies} movies\")\n",
    "print(f\"{n_ratings} ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4BfJL9wScZU"
   },
   "source": [
    "Shuffle the data (see the function [`np.random.shuffle`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.shuffle.html)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1666349397663,
     "user_tz": -120
    },
    "id": "zXgd2S5jSiKE"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)  # for reproducibility\n",
    "\n",
    "idxs = np.arange(n_ratings)\n",
    "np.random.shuffle(idxs)\n",
    "rows_dupes = dataset.user_id[idxs]\n",
    "cols_dupes = dataset.item_id[idxs]\n",
    "vals = dataset.rating[idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unused `user_id` or `movie_id` from `rows` and `cols`. E.g., if we have a dataset like\n",
    "\n",
    "```\n",
    "user id | item id | rating \n",
    "0       |      1  |     4  \n",
    "0       |      2  |     5  \n",
    "3       |      2  |     5  \n",
    "```\n",
    "Then we would have two empty rows in the matrix (for user 1 and 2) and one empty column (for movie 0).\n",
    "```\n",
    "A = [\n",
    "  [0 4 5],\n",
    "  [0 0 0],\n",
    "  [0 0 0],\n",
    "  [0 ? 5],\n",
    "]\n",
    "```\n",
    "Thus, we want to remove empty intervals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, rows = np.unique(rows_dupes, return_inverse=True)\n",
    "_, cols = np.unique(cols_dupes, return_inverse=True)\n",
    "\n",
    "print(rows.min(), rows.max(), n_people)\n",
    "print(cols.min(), cols.max(), n_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Orx1_BciSkTl"
   },
   "source": [
    "Split the dataset into a subset of 80000 training ratings and 20000 testing ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1666349397664,
     "user_tz": -120
    },
    "id": "6NBGJmmsSrNV"
   },
   "outputs": [],
   "source": [
    "training_data = int(0.8 * n_ratings) # use 80% of the data as training\n",
    "\n",
    "rows_train = rows[:training_data]\n",
    "cols_train = cols[:training_data]\n",
    "vals_train = vals[:training_data]\n",
    "rows_test = rows[training_data:]\n",
    "cols_test = cols[training_data:]\n",
    "vals_test = vals[training_data:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fu5h_yrnSwAZ"
   },
   "source": [
    "Let us denote by $\\Omega$ the set of pairs $(i,j)$ such that rating of the $i$-th user on the $j$-th movie is available in the training set (similarly, $\\Omega_{\\text{test}}$ is the set of testing pairs).\n",
    "Let us denote by $r_{ij}$ the corresponding rating.\n",
    "\n",
    "Create a full matrix $X \\in \\mathbb{R}^{n \\times p}$, such that:\n",
    "\n",
    "$$\n",
    "X_{i,j} =\n",
    "\\begin{cases}\n",
    "r_{ij} & \\text{if } (i,j) \\in \\Omega\\\\\n",
    "0& \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1666349397664,
     "user_tz": -120
    },
    "id": "A7wrWIjmTR_r"
   },
   "outputs": [],
   "source": [
    "X_sparse = csr_matrix((vals_train, (rows_train, cols_train)), shape=(n_people, n_movies))\n",
    "X_full = X_sparse.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGg4nEkKTSWK"
   },
   "source": [
    "## Trivial recommender system\n",
    "\n",
    "Create a trivial recommender system, based on the average rating of each user:\n",
    "\n",
    "$$\n",
    "r^{\\text{pred}}_{ij} = \\frac{1}{N_i} \\sum_{j : (i,j) \\in \\Omega} r_{ij}\n",
    "$$\n",
    "\n",
    "where $N_i = card(j : (i,j) \\in \\Omega)$.\n",
    "\n",
    "Then compute the RMSE (root mean square error):\n",
    "\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{card(\\Omega_{\\text{test}})} \\sum_{(i,j) \\in \\Omega_{\\text{test}}} (r_{ij} - r^{\\text{pred}}_{ij})^2}\n",
    "$$\n",
    "\n",
    "and the Pearson correlation coefficient $\\rho$ (use the function [scipy.stats.pearsonr](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html)):\n",
    "\n",
    "$$\n",
    "\\rho =\n",
    "\\frac\n",
    "{\n",
    "    \\displaystyle\\sum_{(i,j) \\in \\Omega_{\\text{test}}}\n",
    "       (r_{ij} - \\overline{r})\n",
    "       (r^{\\text{pred}}_{ij} - \\overline{r}^{\\text{pred}})\n",
    "}\n",
    "{\\sqrt{\n",
    "    \\displaystyle\\sum_{(i,j) \\in \\Omega_{\\text{test}}}\n",
    "       (r_{ij} - \\overline{r})^2\n",
    "       }\n",
    "\\sqrt{\n",
    "    \\displaystyle\\sum_{(i,j) \\in \\Omega_{\\text{test}}}\n",
    "       (r^{\\text{pred}}_{ij} - \\overline{r}^{\\text{pred}})^2\n",
    "       }}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\overline{r} &= \\frac{1}{card(\\Omega_{\\text{test}})} \\sum_{(i,j) \\in \\Omega_{\\text{test}}}\n",
    "       r_{ij}\n",
    "\\\\\n",
    "\\overline{r}^{\\text{pred}} &= \\frac{1}{card(\\Omega_{\\text{test}})} \\sum_{(i,j) \\in \\Omega_{\\text{test}}}\n",
    "       r^{\\text{pred}}_{ij}\n",
    "\\end{split}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1666349397916,
     "user_tz": -120
    },
    "id": "jHMRByIcqPRT",
    "outputId": "cfee7cb5-49bb-470e-cf81-ebc3c5ba94f9"
   },
   "outputs": [],
   "source": [
    "# compute trivial predictor on the training dataset\n",
    "# SOLUTION-BEGIN\n",
    "avg_ratings = np.empty((n_people,))\n",
    "for user_id in range(n_people):\n",
    "  avg_ratings[user_id] = np.mean(vals_train[rows_train == user_id])\n",
    "\n",
    "# The vectorized version\n",
    "# sum_ratings = np.bincount(rows_train, weights=vals_train, minlength=n_people)\n",
    "# count_ratings = np.bincount(rows_train, minlength=n_people)\n",
    "# avg_ratings = sum_ratings / count_ratings\n",
    "\n",
    "# use the trivial predictor on the test dataset\n",
    "vals_trivial = avg_ratings[rows_test]\n",
    "# SOLUTION-END\n",
    "\n",
    "errors_trivial = vals_test - vals_trivial\n",
    "\n",
    "# print the metrics\n",
    "RMSE_trivial = np.sqrt(np.mean(errors_trivial**2))\n",
    "rho_trivial = pearsonr(vals_test, vals_trivial)[0]\n",
    "print(f\"RMSE: {RMSE_trivial:1.3f}\")\n",
    "print(f\"rho : {rho_trivial:1.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQxUcttequN3"
   },
   "source": [
    "# Singular value truncation (SVT) based recommender system\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLtvKy_kqz2D"
   },
   "source": [
    "Implement the SVT algorithm to predict the ratings of the testing set. Set a maximum number of iterations equal to 100. Print the RMSE and $\\rho$ at each iteration.\n",
    "\n",
    "Try to calibrate the threshold to get better results.\n",
    "\n",
    "Sketch of the SVT steps:\n",
    "1. $U \\Sigma V^T = A$\n",
    "2. $\\displaystyle A = \\sum_{k : \\sigma_k < \\texttt{threshold}} \\sigma_k u_k v_k$\n",
    "3. $A_{ij} = X_{ij}$ for all $i, j$ in the training dataset\n",
    "4. Compute the difference w.r.t. the $A$ at the previous step\n",
    "5. Compute and save the test metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 155210,
     "status": "ok",
     "timestamp": 1666349553124,
     "user_tz": -120
    },
    "id": "0vXEQDwBPuru",
    "outputId": "f50a9ee8-678f-4db5-c98a-b48643f35862"
   },
   "outputs": [],
   "source": [
    "n_max_iter = 100\n",
    "threshold = 100.0\n",
    "increment_tol = 1e-6\n",
    "\n",
    "RMSE_list = list()\n",
    "rho_list = list()\n",
    "\n",
    "A = X_full.copy()\n",
    "\n",
    "print(\"Iter | Increment |  RMSE |  Corr \")\n",
    "for i in range(n_max_iter):\n",
    "    # SOLUTION-BEGIN\n",
    "    A_old = A.copy()\n",
    "    # HOMEWORK: what happens if you use rSVD here? which is a good k?\n",
    "    U, s, VT = np.linalg.svd(A, full_matrices=False)\n",
    "\n",
    "    # HOMEWORK: can you do this in a quicker way? \n",
    "    # HINT: we are wasting time summing zeros\n",
    "    s[s < threshold] = 0\n",
    "    A = U @ np.diag(s) @ VT\n",
    "\n",
    "    A[rows_train, cols_train] = vals_train\n",
    "    increment = np.linalg.norm(A - A_old)\n",
    "\n",
    "    vals_predicted = A[rows_test, cols_test]\n",
    "    errors = vals_test - vals_predicted\n",
    "\n",
    "    RMSE_list.append(np.sqrt(np.mean(errors**2)))\n",
    "    rho_list.append(pearsonr(vals_test, vals_predicted)[0])\n",
    "    # SOLUTION-END\n",
    "\n",
    "    print(f\"{i+1:04} | {increment:.3e} | {RMSE_list[-1]:1.3f} | {rho_list[-1]:1.3f}\")\n",
    "    if increment < increment_tol:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the history of RMSE and $\\rho$ and confront it with the trivial predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939
    },
    "executionInfo": {
     "elapsed": 1582,
     "status": "ok",
     "timestamp": 1666349554698,
     "user_tz": -120
    },
    "id": "A7gFTlv0sKzz",
    "outputId": "2ee1ad08-0cbe-456c-f7d1-d239f99d1c8c"
   },
   "outputs": [],
   "source": [
    "# SOLUTION-BEGIN\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12, 16))\n",
    "\n",
    "axs[0].plot(RMSE_list, \"o-\")\n",
    "axs[0].axhline(RMSE_trivial, color=\"red\")\n",
    "axs[0].legend([\"RMSE\", \"RMSE trivial\"])\n",
    "\n",
    "axs[1].plot(rho_list, \"o-\")\n",
    "axs[1].axhline(rho_trivial, color=\"red\")\n",
    "axs[1].legend([r\"$\\rho$\", r\"$\\rho$ trivial\"])\n",
    "# SOLUTION-END"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPZHuOGF9tSgt8eA2rwZCBm",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
