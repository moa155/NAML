{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ky2ALT8aFZq"
   },
   "source": [
    "# Handwriting recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 861,
     "status": "ok",
     "timestamp": 1671127675776,
     "user_tz": -60
    },
    "id": "3uD05d77CfLv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import optax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWxlDFYZx31S"
   },
   "source": [
    "### Data import and visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRNhX9i6vwuT"
   },
   "source": [
    "Import the MNIST train dataset ([https://en.wikipedia.org/wiki/MNIST_database](https://en.wikipedia.org/wiki/MNIST_database))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28648,
     "status": "ok",
     "timestamp": 1671127704421,
     "user_tz": -60
    },
    "id": "Tb2dI5WU-2ji",
    "outputId": "d3e06508-739e-44e1-e424-430eb7f49f15"
   },
   "outputs": [],
   "source": [
    "# This dataset is contained in the sample data directory of Google Colab online runtimes\n",
    "data = np.genfromtxt(\"./mnist_train_small.csv\", delimiter=\",\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtWMNidPv9y_"
   },
   "source": [
    "Store the data in a 4-th order tensor (samples, x-pixel, y-pixel, channels) and the labels in a vector.\n",
    "**NOTE:** The labels are the first column of the data matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1671127704421,
     "user_tz": -60
    },
    "id": "yzGMpNrABkpe",
    "outputId": "dc3a2606-1700-493e-d696-3829741bbe08"
   },
   "outputs": [],
   "source": [
    "# SOLUTION-BEGIN\n",
    "labels = data[:, 0]\n",
    "x_data = data[:, 1:].reshape((-1, 28, 28, 1)) / 255\n",
    "labels.shape, x_data.shape\n",
    "# SOLUTION-END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9AwDHzcwSx3"
   },
   "source": [
    "Visualize the first 30 pictures with the corresponding labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "executionInfo": {
     "elapsed": 1518,
     "status": "ok",
     "timestamp": 1671127705936,
     "user_tz": -60
    },
    "id": "Nd6cnbmu_Gvv",
    "outputId": "6a02815d-3ff1-490e-e93c-33976477205e"
   },
   "outputs": [],
   "source": [
    "# SOLUTION-BEGIN\n",
    "fig, axs = plt.subplots(ncols=10, nrows=3, figsize=(20, 6))\n",
    "axs = axs.reshape((-1,))\n",
    "for i in range(30):\n",
    "    image_i = x_data[i]\n",
    "    axs[i].imshow(image_i, cmap=\"gray\")\n",
    "    axs[i].set_title(int(labels[i]))\n",
    "    axs[i].axis(\"off\")\n",
    "# SOLUTION-END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8lATi3kOnBs"
   },
   "source": [
    "Create a [one-hot](https://en.wikipedia.org/wiki/One-hot) representation of the labels, that is a matrix where each row corresponds to a class (i.e. a digit).\n",
    "the entries of the matrix are 1 if the sample corresponds to that digit, 0 otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1671127705936,
     "user_tz": -60
    },
    "id": "fvaLuITMCstt"
   },
   "outputs": [],
   "source": [
    "# SOLUTION-BEGIN\n",
    "labels_onehot = np.zeros((20000, 10))\n",
    "for i in range(10):\n",
    "    labels_onehot[labels == i, i] = 1\n",
    "# SOLUTION-END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZGpB1VwSceh"
   },
   "source": [
    "Check that the matrix has exactly one element \"1\" in each row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1671127705937,
     "user_tz": -60
    },
    "id": "Exa59aV0SYHq",
    "outputId": "d2a9add3-ee46-4e0f-e61a-e2f3f9bc42b0"
   },
   "outputs": [],
   "source": [
    "# SOLUTION-BEGIN\n",
    "row_sums = np.sum(labels_onehot, axis=1)\n",
    "row_sums.min(), row_sums.max()\n",
    "# SOLUTION-END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDkeuzgpTonk"
   },
   "source": [
    "### ANN training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the architecture of the neural network.\n",
    "For more details on CNNs see https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1671127705937,
     "user_tz": -60
    },
    "id": "8j6cWbYdB-q_"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape((x.shape[0], -1))  # Flatten\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "\n",
    "        # The `softmax_cross_entropy` expects unnormalized logits.\n",
    "        # There is also the `softmax_cross_entropy_with_integer_labels`\n",
    "        # version that uses integers target labels.\n",
    "        # If you apply a softmax first, you turn logits into probabilities, and the\n",
    "        # loss might becomes numerically unstable and incorrect. Optax/JAX expects to\n",
    "        # handle the softmax internally in a stable way (using logsumexp tricks).\n",
    "        x = nn.Dense(features=10)(x)  # There are 10 classes in MNIST\n",
    "        return x\n",
    "\n",
    "\n",
    "cnn = CNN()\n",
    "\n",
    "table = cnn.tabulate(\n",
    "    jax.random.PRNGKey(0), jnp.zeros((1, 28, 28, 1)), console_kwargs={\"width\": 200}\n",
    ")\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to compute the **cross entropy loss** and the **accuracy** of the model given as parameters the unormalized logits (the output of the CNN) and the one-hot encoded target value. To compute the loss you can exploit `optax.softmax_cross_entropy`, check the documentation for the details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(logits, labels_onehot):\n",
    "    # SOLUTION-BEGIN\n",
    "    loss = jnp.mean(optax.softmax_cross_entropy(logits, labels_onehot))\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == jnp.argmax(labels_onehot, -1))\n",
    "    # SOLUTION-END\n",
    "    return {\"loss\": loss, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define functions used for the training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def loss_fn(params, x, y):\n",
    "    # SOLUTION-BEGIN\n",
    "    logits = cnn.apply({\"params\": params}, x)\n",
    "    loss = jnp.mean(optax.softmax_cross_entropy(logits=logits, labels=y))\n",
    "    # SOLUTION-END\n",
    "    return loss, logits\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, x, y):\n",
    "    # SOLUTION-BEGIN\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (_, logits), grads = grad_fn(state.params, x, y)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    metrics = compute_metrics(logits, y)\n",
    "    # SOLUTION-END\n",
    "    return state, metrics\n",
    "\n",
    "\n",
    "def eval_model(state, dataset):\n",
    "    # SOLUTION-BEGIN\n",
    "    logits = state.apply_fn({\"params\": state.params}, dataset[\"image\"])\n",
    "    metrics = compute_metrics(logits, dataset[\"label\"])\n",
    "    # SOLUTION-END\n",
    "    return metrics[\"loss\"], metrics[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function for one training epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(state, train_ds, batch_size, epoch, rng):\n",
    "    # SOLUTION-BEGIN\n",
    "    train_ds_size = len(train_ds[\"image\"])\n",
    "    steps_per_epoch = train_ds_size // batch_size\n",
    "\n",
    "    perms = jax.random.permutation(rng, len(train_ds[\"image\"]))\n",
    "    perms = perms[: steps_per_epoch * batch_size]\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "\n",
    "    batch_metrics = []\n",
    "\n",
    "    for perm in perms:\n",
    "        batch = {k: v[perm, ...] for k, v in train_ds.items()}\n",
    "        state, metrics = train_step(state, batch[\"image\"], batch[\"label\"])\n",
    "        batch_metrics.append(metrics)\n",
    "\n",
    "    training_epoch_metrics = {\n",
    "        k: np.mean([metrics[k] for metrics in batch_metrics])\n",
    "        for k in batch_metrics[0]\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        f\"{epoch:04}  | \"\n",
    "        f\"{training_epoch_metrics['loss']:.4e} | \"\n",
    "        f\"    {training_epoch_metrics['accuracy'] * 100:.2f} | \",\n",
    "        end=\"\"\n",
    "    )\n",
    "\n",
    "    # SOLUTION-END\n",
    "\n",
    "    return state, training_epoch_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data by randomizing and creating the train-validation split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# SOLUTION-BEGIN\n",
    "n_samples = x_data.shape[0]\n",
    "perm = np.random.permutation(n_samples)\n",
    "train_perc = 0.8\n",
    "n_train_samples = int(train_perc * n_samples)\n",
    "train_idxs = perm[:n_train_samples]\n",
    "valid_idx = perm[n_train_samples:]\n",
    "# SOLUTION-END\n",
    "\n",
    "train_ds = {\n",
    "    \"image\": jnp.array(x_data[train_idxs]),\n",
    "    \"label\": jnp.array(labels_onehot[train_idxs], dtype=jnp.float32),\n",
    "}\n",
    "valid_ds = {\n",
    "    \"image\": jnp.array(x_data[valid_idx]),\n",
    "    \"label\": jnp.array(labels_onehot[valid_idx], dtype=jnp.float32),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "\n",
    "# Initialize lists to store metrics for graph visualization\n",
    "training_losses = []\n",
    "training_accuracies = []\n",
    "valid_losses = []\n",
    "valid_accuracies = []\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize the CNN and optimizer\n",
    "# SOLUTION-BEGIN\n",
    "params = cnn.init(init_rng, jnp.ones([1, 28, 28, 1]))[\"params\"]\n",
    "tx = optax.adam(learning_rate=learning_rate)\n",
    "state = train_state.TrainState.create(apply_fn=cnn.apply, params=params, tx=tx)\n",
    "# SOLUTION-END\n",
    "\n",
    "print(\"epoch | train loss | train acc | valid loss | valid acc\")\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # SOLUTION-BEGIN\n",
    "    # Use a separate PRNG key to permute image data during shuffling\n",
    "    rng, input_rng = jax.random.split(rng)\n",
    "    # Run an optimization step over a training batch\n",
    "    state, train_metrics = train_epoch(state, train_ds, batch_size, epoch, input_rng)\n",
    "    # Evaluate on the test set after each training epoch\n",
    "    valid_loss, valid_accuracy = eval_model(state, valid_ds)\n",
    "    print(\n",
    "        f\"{valid_loss:.4e} | \" f\"{valid_accuracy * 100:.2f}\",\n",
    "    )\n",
    "    # Store metrics for graph visualization\n",
    "    training_losses.append(train_metrics[\"loss\"])\n",
    "    training_accuracies.append(train_metrics[\"accuracy\"])\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accuracies.append(valid_accuracy)\n",
    "    # SOLUTION-END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYN_CQrCs7TR"
   },
   "source": [
    "## Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLLoZBE70wmM"
   },
   "source": [
    "Load the dataset `sample_data/mnist_test.csv` and normalize and shape the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6928,
     "status": "ok",
     "timestamp": 1671127740354,
     "user_tz": -60
    },
    "id": "P-KXleHts6xy",
    "outputId": "7bb220b2-e71e-4e1f-be9e-a056191ac874"
   },
   "outputs": [],
   "source": [
    "data_test = np.genfromtxt(\"./mnist_test.csv\", delimiter=\",\")\n",
    "data_test.shape\n",
    "labels_test = data_test[:, 0]\n",
    "x_test = data_test[:, 1:] / 255\n",
    "\n",
    "labels_onehot_test = np.zeros((x_test.shape[0], 10))\n",
    "for i in range(10):\n",
    "    labels_onehot_test[labels_test == i, i] = 1.0\n",
    "\n",
    "\n",
    "test_ds = {\n",
    "    \"image\": jnp.array(x_test.reshape((-1, 28, 28, 1))),\n",
    "    \"label\": jnp.array(labels_onehot_test),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy of the classifier on this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 429,
     "status": "ok",
     "timestamp": 1671127740780,
     "user_tz": -60
    },
    "id": "2pAqC6XztA0o",
    "outputId": "1ca072d1-bc8a-4b5e-bded-e27b4302d886"
   },
   "outputs": [],
   "source": [
    "# SOLUTION-BEGIN\n",
    "test_loss, test_accuracy = eval_model(state, test_ds)\n",
    "print(f\"Loss: {test_loss:.2e}\")\n",
    "print(f\"Accuracy: {test_accuracy * 100.:.2f}%\")\n",
    "# SOLUTION-END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJSRUqyE08r4"
   },
   "source": [
    "Use the following script to visualize the predictions on a bunch of test images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7608,
     "status": "ok",
     "timestamp": 1671127748387,
     "user_tz": -60
    },
    "id": "2AIAKPAStXfz",
    "outputId": "703738b1-8183-4403-a7d6-c8fdcf9f2756"
   },
   "outputs": [],
   "source": [
    "offset = 0\n",
    "n_images = 40\n",
    "\n",
    "images_per_row = 10\n",
    "y_predicted = state.apply_fn({\"params\": state.params}, test_ds[\"image\"])\n",
    "\n",
    "\n",
    "def draw_bars(ax, y_predicted, label):\n",
    "    myplot = ax.bar(range(10), (y_predicted))\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_xticks(range(10))\n",
    "\n",
    "    label_predicted = np.argmax(y_predicted)\n",
    "    if label == label_predicted:\n",
    "        color = \"green\"\n",
    "    else:\n",
    "        color = \"red\"\n",
    "    myplot[label_predicted].set_color(color)\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "n_rows = 2 * math.ceil(n_images / images_per_row)\n",
    "_, axs = plt.subplots(n_rows, images_per_row, figsize=(3 * images_per_row, 3 * n_rows))\n",
    "row = 0\n",
    "col = 0\n",
    "for i in range(n_images):\n",
    "    axs[2 * row, col].imshow(x_test[offset + i].reshape((28, 28)), cmap=\"gray\")\n",
    "    axs[2 * row, col].set_title(int(labels_test[offset + i]))\n",
    "    axs[2 * row, col].axis(\"off\")\n",
    "\n",
    "    draw_bars(\n",
    "        axs[2 * row + 1, col], jax.nn.softmax(y_predicted[i]), labels_test[offset + i]\n",
    "    )\n",
    "\n",
    "    col += 1\n",
    "    if col == images_per_row:\n",
    "        col = 0\n",
    "        row += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1yZaDFFKKBk"
   },
   "source": [
    "# Adversarial attacks\n",
    "\n",
    "You have trained your classifier. Cool, isn't it? Let us now try to fool it.\n",
    "\n",
    "An adversarial attack consists of an (almost imperceptible) modification of the image, aimed at fooling the classifier into making a mistake.\n",
    "See e.g. [this article](https://www.wired.com/story/tesla-speed-up-adversarial-example-mgm-breach-ransomware/)\n",
    "\n",
    "To hack the classifier, compute the gradient of cross entropy loss funcion with respect to the input (not to the parameters!). Then, superimpose a multiple of the gradient to the original image. See e.g. [this article](https://www.tensorflow.org/tutorials/generative/adversarial_fgsm).\n",
    "\n",
    "Namely, follow these steps:\n",
    "\n",
    "1. Compute the gradient of `loss_fn` with respect to the **input of the CNN (the image)**\n",
    "2. Compute the perturbed image, by summing $\\epsilon \\text{ sign}(\\nabla_x \\texttt{loss\\_fn})$\n",
    "3. Clip the result in $[0, 1]$\n",
    "\n",
    "Visualize the original and the hacked images and the corresponding prediction of the classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# FGSM attack\n",
    "def fgsm_attack(params, image, label, epsilon):\n",
    "    # SOLUTION-BEGIN\n",
    "    # Compute gradient of loss w.r.t. the input image\n",
    "    grad_fn = jax.grad(lambda img: loss_fn(params, img, label), has_aux=True)\n",
    "\n",
    "    gradient, _ = grad_fn(image)\n",
    "\n",
    "    # Apply perturbation\n",
    "    adv_image = image + epsilon * jnp.sign(gradient)\n",
    "\n",
    "    # Clip back to valid pixel range\n",
    "    adv_image = jnp.clip(adv_image, 0.0, 1.0)\n",
    "    # SOLUTION-END\n",
    "    return adv_image\n",
    "\n",
    "\n",
    "# By trial-and-error I give you the information that for the following images\n",
    "# an `epsilon = 0.05` is large enough to fool the CNN\n",
    "epsilon = 0.05\n",
    "for idx in [11, 66, 115, 244]:\n",
    "    # SOLUTION-BEGIN\n",
    "    x = test_ds[\"image\"][idx : idx + 1]\n",
    "    y = test_ds[\"label\"][idx]\n",
    "\n",
    "    # True prediction\n",
    "    logits = cnn.apply({\"params\": state.params}, x)\n",
    "    true_pred = jnp.argmax(logits, axis=-1)\n",
    "    print(\"Original prediction:\", true_pred)\n",
    "\n",
    "    # Create adversarial example\n",
    "    x_adv = fgsm_attack(state.params, x, y, epsilon)\n",
    "\n",
    "    # Prediction on adversarial image\n",
    "    logits_adv = cnn.apply({\"params\": state.params}, x_adv)\n",
    "    adv_pred = jnp.argmax(logits_adv, axis=-1)\n",
    "    print(\"Adversarial prediction:\", adv_pred)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f\"Original ({true_pred})\")\n",
    "    plt.imshow(x[0, :, :, 0], cmap=\"gray\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f\"Adversarial ({adv_pred})\")\n",
    "    plt.imshow(x_adv[0, :, :, 0], cmap=\"gray\")\n",
    "\n",
    "    plt.show()\n",
    "    # SOLUTION-END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_layer_output(cnn_module, params, input_data):\n",
    "    \"\"\"\n",
    "    Manually applies the first convolutional layer and ReLU.\n",
    "    \"\"\"\n",
    "    # 1. Access the first Conv layer from the parameters\n",
    "    # The name of the first Conv layer is typically 'Conv_0' by default in Flax\n",
    "    # if it's the first nn.Conv without an explicit name.\n",
    "    \n",
    "    # Instantiate the first Conv layer with the correct features and kernel size\n",
    "    conv_layer = nn.Conv(features=32, kernel_size=(3, 3), name='Conv_0')\n",
    "\n",
    "    # Apply the convolution using the parameters (weights and biases)\n",
    "    # This requires using the `apply` method of the layer and passing the specific subset of parameters\n",
    "    conv_output = conv_layer.apply({'params': params['Conv_0']}, input_data)\n",
    "    \n",
    "    # 2. Apply ReLU\n",
    "    final_output = nn.relu(conv_output)\n",
    "    \n",
    "    return final_output\n",
    "\n",
    "idx = 0\n",
    "first_layer_output = get_first_layer_output(cnn, state.params, test_ds[\"image\"][idx : idx + 1])\n",
    "first_layer_output.shape\n",
    "\n",
    "for i in range(32):\n",
    "    plt.figure()\n",
    "    plt.imshow(first_layer_output[0, :, :, i])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMrG9ECGJ+Egk3Zy2waV0G7",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
