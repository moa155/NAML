{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ky2ALT8aFZq"
   },
   "source": [
    "# Handwriting recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 861,
     "status": "ok",
     "timestamp": 1671127675776,
     "user_tz": -60
    },
    "id": "3uD05d77CfLv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import optax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWxlDFYZx31S"
   },
   "source": [
    "### Data import and visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRNhX9i6vwuT"
   },
   "source": [
    "Import the MNIST train dataset ([https://en.wikipedia.org/wiki/MNIST_database](https://en.wikipedia.org/wiki/MNIST_database))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28648,
     "status": "ok",
     "timestamp": 1671127704421,
     "user_tz": -60
    },
    "id": "Tb2dI5WU-2ji",
    "outputId": "d3e06508-739e-44e1-e424-430eb7f49f15"
   },
   "outputs": [],
   "source": [
    "# This dataset is contained in the sample data directory of Google Colab online runtimes\n",
    "data = np.genfromtxt(\"./mnist_train_small.csv\", delimiter=\",\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtWMNidPv9y_"
   },
   "source": [
    "Store the data in a 4-th order tensor (samples, x-pixel, y-pixel, channels) and the labels in a vector.\n",
    "**NOTE:** The labels are the first column of the data matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1671127704421,
     "user_tz": -60
    },
    "id": "yzGMpNrABkpe",
    "outputId": "dc3a2606-1700-493e-d696-3829741bbe08"
   },
   "outputs": [],
   "source": [
    "# FILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9AwDHzcwSx3"
   },
   "source": [
    "Visualize the first 30 pictures with the corresponding labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "executionInfo": {
     "elapsed": 1518,
     "status": "ok",
     "timestamp": 1671127705936,
     "user_tz": -60
    },
    "id": "Nd6cnbmu_Gvv",
    "outputId": "6a02815d-3ff1-490e-e93c-33976477205e"
   },
   "outputs": [],
   "source": [
    "# FILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8lATi3kOnBs"
   },
   "source": [
    "Create a [one-hot](https://en.wikipedia.org/wiki/One-hot) representation of the labels, that is a matrix where each row corresponds to a class (i.e. a digit).\n",
    "the entries of the matrix are 1 if the sample corresponds to that digit, 0 otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1671127705936,
     "user_tz": -60
    },
    "id": "fvaLuITMCstt"
   },
   "outputs": [],
   "source": [
    "# FILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZGpB1VwSceh"
   },
   "source": [
    "Check that the matrix has exactly one element \"1\" in each row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1671127705937,
     "user_tz": -60
    },
    "id": "Exa59aV0SYHq",
    "outputId": "d2a9add3-ee46-4e0f-e61a-e2f3f9bc42b0"
   },
   "outputs": [],
   "source": [
    "# FILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDkeuzgpTonk"
   },
   "source": [
    "### ANN training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the architecture of the neural network.\n",
    "For more details on CNNs see https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1671127705937,
     "user_tz": -60
    },
    "id": "8j6cWbYdB-q_"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape((x.shape[0], -1))  # Flatten\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "\n",
    "        # The `softmax_cross_entropy` expects unnormalized logits.\n",
    "        # There is also the `softmax_cross_entropy_with_integer_labels`\n",
    "        # version that uses integers target labels.\n",
    "        # If you apply a softmax first, you turn logits into probabilities, and the\n",
    "        # loss might becomes numerically unstable and incorrect. Optax/JAX expects to\n",
    "        # handle the softmax internally in a stable way (using logsumexp tricks).\n",
    "        x = nn.Dense(features=10)(x)  # There are 10 classes in MNIST\n",
    "        return x\n",
    "\n",
    "\n",
    "cnn = CNN()\n",
    "\n",
    "table = cnn.tabulate(\n",
    "    jax.random.PRNGKey(0), jnp.zeros((1, 28, 28, 1)), console_kwargs={\"width\": 200}\n",
    ")\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to compute the **cross entropy loss** and the **accuracy** of the model given as parameters the unormalized logits (the output of the CNN) and the one-hot encoded target value. To compute the loss you can exploit `optax.softmax_cross_entropy`, check the documentation for the details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(logits, labels_onehot):\n",
    "# FILL HERE\n",
    "    return {\"loss\": loss, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define functions used for the training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def loss_fn(params, x, y):\n",
    "# FILL HERE\n",
    "    return loss, logits\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, x, y):\n",
    "# FILL HERE\n",
    "    return state, metrics\n",
    "\n",
    "\n",
    "def eval_model(state, dataset):\n",
    "# FILL HERE\n",
    "    return metrics[\"loss\"], metrics[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function for one training epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(state, train_ds, batch_size, epoch, rng):\n",
    "# FILL HERE\n",
    "\n",
    "    return state, training_epoch_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data by randomizing and creating the train-validation split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# FILL HERE\n",
    "\n",
    "train_ds = {\n",
    "    \"image\": jnp.array(x_data[train_idxs]),\n",
    "    \"label\": jnp.array(labels_onehot[train_idxs], dtype=jnp.float32),\n",
    "}\n",
    "valid_ds = {\n",
    "    \"image\": jnp.array(x_data[valid_idx]),\n",
    "    \"label\": jnp.array(labels_onehot[valid_idx], dtype=jnp.float32),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "\n",
    "# Initialize lists to store metrics for graph visualization\n",
    "training_losses = []\n",
    "training_accuracies = []\n",
    "valid_losses = []\n",
    "valid_accuracies = []\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize the CNN and optimizer\n",
    "# FILL HERE\n",
    "\n",
    "print(\"epoch | train loss | train acc | valid loss | valid acc\")\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "# FILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYN_CQrCs7TR"
   },
   "source": [
    "## Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLLoZBE70wmM"
   },
   "source": [
    "Load the dataset `sample_data/mnist_test.csv` and normalize and shape the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6928,
     "status": "ok",
     "timestamp": 1671127740354,
     "user_tz": -60
    },
    "id": "P-KXleHts6xy",
    "outputId": "7bb220b2-e71e-4e1f-be9e-a056191ac874"
   },
   "outputs": [],
   "source": [
    "data_test = np.genfromtxt(\"./mnist_test.csv\", delimiter=\",\")\n",
    "data_test.shape\n",
    "labels_test = data_test[:, 0]\n",
    "x_test = data_test[:, 1:] / 255\n",
    "\n",
    "labels_onehot_test = np.zeros((x_test.shape[0], 10))\n",
    "for i in range(10):\n",
    "    labels_onehot_test[labels_test == i, i] = 1.0\n",
    "\n",
    "\n",
    "test_ds = {\n",
    "    \"image\": jnp.array(x_test.reshape((-1, 28, 28, 1))),\n",
    "    \"label\": jnp.array(labels_onehot_test),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy of the classifier on this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 429,
     "status": "ok",
     "timestamp": 1671127740780,
     "user_tz": -60
    },
    "id": "2pAqC6XztA0o",
    "outputId": "1ca072d1-bc8a-4b5e-bded-e27b4302d886"
   },
   "outputs": [],
   "source": [
    "# FILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJSRUqyE08r4"
   },
   "source": [
    "Use the following script to visualize the predictions on a bunch of test images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7608,
     "status": "ok",
     "timestamp": 1671127748387,
     "user_tz": -60
    },
    "id": "2AIAKPAStXfz",
    "outputId": "703738b1-8183-4403-a7d6-c8fdcf9f2756"
   },
   "outputs": [],
   "source": [
    "offset = 0\n",
    "n_images = 40\n",
    "\n",
    "images_per_row = 10\n",
    "y_predicted = state.apply_fn({\"params\": state.params}, test_ds[\"image\"])\n",
    "\n",
    "\n",
    "def draw_bars(ax, y_predicted, label):\n",
    "    myplot = ax.bar(range(10), (y_predicted))\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_xticks(range(10))\n",
    "\n",
    "    label_predicted = np.argmax(y_predicted)\n",
    "    if label == label_predicted:\n",
    "        color = \"green\"\n",
    "    else:\n",
    "        color = \"red\"\n",
    "    myplot[label_predicted].set_color(color)\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "n_rows = 2 * math.ceil(n_images / images_per_row)\n",
    "_, axs = plt.subplots(n_rows, images_per_row, figsize=(3 * images_per_row, 3 * n_rows))\n",
    "row = 0\n",
    "col = 0\n",
    "for i in range(n_images):\n",
    "    axs[2 * row, col].imshow(x_test[offset + i].reshape((28, 28)), cmap=\"gray\")\n",
    "    axs[2 * row, col].set_title(int(labels_test[offset + i]))\n",
    "    axs[2 * row, col].axis(\"off\")\n",
    "\n",
    "    draw_bars(\n",
    "        axs[2 * row + 1, col], jax.nn.softmax(y_predicted[i]), labels_test[offset + i]\n",
    "    )\n",
    "\n",
    "    col += 1\n",
    "    if col == images_per_row:\n",
    "        col = 0\n",
    "        row += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1yZaDFFKKBk"
   },
   "source": [
    "# Adversarial attacks\n",
    "\n",
    "You have trained your classifier. Cool, isn't it? Let us now try to fool it.\n",
    "\n",
    "An adversarial attack consists of an (almost imperceptible) modification of the image, aimed at fooling the classifier into making a mistake.\n",
    "See e.g. [this article](https://www.wired.com/story/tesla-speed-up-adversarial-example-mgm-breach-ransomware/)\n",
    "\n",
    "To hack the classifier, compute the gradient of cross entropy loss funcion with respect to the input (not to the parameters!). Then, superimpose a multiple of the gradient to the original image. See e.g. [this article](https://www.tensorflow.org/tutorials/generative/adversarial_fgsm).\n",
    "\n",
    "Namely, follow these steps:\n",
    "\n",
    "1. Compute the gradient of `loss_fn` with respect to the **input of the CNN (the image)**\n",
    "2. Compute the perturbed image, by summing $\\epsilon \\text{ sign}(\\nabla_x \\texttt{loss\\_fn})$\n",
    "3. Clip the result in $[0, 1]$\n",
    "\n",
    "Visualize the original and the hacked images and the corresponding prediction of the classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# FGSM attack\n",
    "def fgsm_attack(params, image, label, epsilon):\n",
    "# FILL HERE\n",
    "    return adv_image\n",
    "\n",
    "\n",
    "# By trial-and-error I give you the information that for the following images\n",
    "# an `epsilon = 0.05` is large enough to fool the CNN\n",
    "epsilon = 0.05\n",
    "for idx in [11, 66, 115, 244]:\n",
    "# FILL HERE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMrG9ECGJ+Egk3Zy2waV0G7",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
